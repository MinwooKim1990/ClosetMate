{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention based Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "class FeatureProcessor:\n",
    "    def __init__(self):\n",
    "        self.scalers = []\n",
    "        \n",
    "    def normalize_and_concatenate(self, feature_vectors):\n",
    "        normalized_vectors = []\n",
    "        \n",
    "        for vector in feature_vectors:\n",
    "            scaler = StandardScaler()\n",
    "            normalized = scaler.fit_transform(vector)\n",
    "            self.scalers.append(scaler)\n",
    "            normalized_vectors.append(normalized)\n",
    "        \n",
    "        return np.concatenate(normalized_vectors, axis=1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.BatchNorm1d(in_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.BatchNorm1d(in_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(x + self.block(x))\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var, kld_weight):\n",
    "    # Use mean reduction instead of sum\n",
    "    reconstruction_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    \n",
    "    # Normalized KLD loss\n",
    "    kld_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    \n",
    "    return reconstruction_loss + kld_weight * kld_loss, reconstruction_loss, kld_loss\n",
    "\n",
    "class WarmUpScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs):\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        super(WarmUpScheduler, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_epochs:\n",
    "            return [base_lr * (self.last_epoch + 1) / self.warmup_epochs \n",
    "                    for base_lr in self.base_lrs]\n",
    "        return [base_lr * (1 - (self.last_epoch - self.warmup_epochs) / \n",
    "                (self.total_epochs - self.warmup_epochs))\n",
    "                for base_lr in self.base_lrs]\n",
    "\n",
    "class GroupedLinearAttention(nn.Module):\n",
    "    def __init__(self, feature_dim, group_size=64):\n",
    "        super().__init__()\n",
    "        self.group_size = group_size\n",
    "        self.num_groups = feature_dim // group_size\n",
    "        if feature_dim % group_size != 0:\n",
    "            self.num_groups += 1\n",
    "        \n",
    "        # Initialize with normal distribution\n",
    "        self.feature_weights = nn.Parameter(torch.randn(feature_dim) * 0.02)\n",
    "        \n",
    "        # Separate projections for each group\n",
    "        self.group_projections = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(group_size, group_size // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(group_size // 2, group_size)\n",
    "            ) for _ in range(self.num_groups)\n",
    "        ])\n",
    "        \n",
    "        # Global feature context\n",
    "        self.global_context = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, feature_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        original_size = x.size(1)\n",
    "        \n",
    "        # Apply global context\n",
    "        global_weights = torch.sigmoid(self.global_context(x))\n",
    "        x = x * global_weights\n",
    "        \n",
    "        # Pad if necessary\n",
    "        padded_len = self.num_groups * self.group_size\n",
    "        if padded_len > original_size:\n",
    "            padding = torch.zeros(batch_size, padded_len - original_size, device=x.device)\n",
    "            x = torch.cat([x, padding], dim=1)\n",
    "        \n",
    "        # Process each group\n",
    "        grouped_output = []\n",
    "        for i in range(self.num_groups):\n",
    "            start_idx = i * self.group_size\n",
    "            end_idx = start_idx + self.group_size\n",
    "            group = x[:, start_idx:end_idx]\n",
    "            \n",
    "            # Apply group-specific attention\n",
    "            group_weights = F.softmax(self.feature_weights[start_idx:end_idx], dim=0)\n",
    "            weighted_group = group * group_weights\n",
    "            \n",
    "            # Apply group transformation\n",
    "            transformed_group = self.group_projections[i](weighted_group)\n",
    "            grouped_output.append(transformed_group)\n",
    "        \n",
    "        # Concatenate results\n",
    "        output = torch.cat(grouped_output, dim=1)\n",
    "        \n",
    "        # Return only original size\n",
    "        return output[:, :original_size]\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        # Apply softmax per group to get more distinct importance values\n",
    "        importances = []\n",
    "        for i in range(self.num_groups):\n",
    "            start_idx = i * self.group_size\n",
    "            end_idx = start_idx + self.group_size\n",
    "            group_weights = F.softmax(self.feature_weights[start_idx:end_idx], dim=0)\n",
    "            importances.append(group_weights)\n",
    "        return torch.cat(importances)\n",
    "\n",
    "class AttentionVAE(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=1024, group_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = GroupedLinearAttention(input_dim, group_size)\n",
    "        \n",
    "        # Revised encoder architecture\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            # First layer: input_dim -> 3072\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, 3072),\n",
    "                nn.LayerNorm(3072),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # Second layer: 3072 -> 3072 (residual)\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3072, 3072),\n",
    "                nn.LayerNorm(3072),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # Third layer: 3072 -> 2048\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3072, 2048),\n",
    "                nn.LayerNorm(2048),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Feature projections for residual connections\n",
    "        self.input_projection = nn.Linear(input_dim, 3072)\n",
    "        \n",
    "        # VAE specific layers\n",
    "        self.fc_mu = nn.Linear(2048, encoding_dim)\n",
    "        self.fc_var = nn.Linear(2048, encoding_dim)\n",
    "        \n",
    "        # Revised decoder architecture\n",
    "        self.decoder = nn.ModuleList([\n",
    "            # First layer: encoding_dim -> 2048\n",
    "            nn.Sequential(\n",
    "                nn.Linear(encoding_dim, 2048),\n",
    "                nn.LayerNorm(2048),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # Second layer: 2048 -> 3072\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2048, 3072),\n",
    "                nn.LayerNorm(3072),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # Third layer: 3072 -> 3072 (residual)\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3072, 3072),\n",
    "                nn.LayerNorm(3072),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            # Output layer: 3072 -> input_dim\n",
    "            nn.Linear(3072, input_dim)\n",
    "        ])\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Apply attention\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        # Project input for residual connection\n",
    "        identity = self.input_projection(x)\n",
    "        \n",
    "        # Apply encoder layers\n",
    "        for i, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            if i == 1:  # Add residual connection after second layer\n",
    "                x = x + identity\n",
    "        \n",
    "        return self.fc_mu(x), self.fc_var(x)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # Apply decoder layers with residual connections\n",
    "        for i, layer in enumerate(self.decoder[:-1]):  # Exclude final layer\n",
    "            z = layer(z)\n",
    "            if i == 2:  # Add residual connection at the third layer\n",
    "                identity = z\n",
    "                z = z + identity\n",
    "        \n",
    "        return self.decoder[-1](z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z), mu, log_var\n",
    "    \n",
    "def train_attention_vae(model, train_loader, num_epochs, learning_rate, device):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kld_loss = 0\n",
    "        \n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            inputs = data[0].to(device)\n",
    "            \n",
    "            # Adaptive KLD weight\n",
    "            kld_weight = min(1.0, (epoch * len(train_loader) + batch_idx) / \n",
    "                           (10 * len(train_loader)))\n",
    "            \n",
    "            # 수정된 autocast 사용\n",
    "            with autocast():\n",
    "                reconstructed, mu, log_var = model(inputs)\n",
    "                loss, recon_loss, kld_loss = loss_function(\n",
    "                    reconstructed, inputs, mu, log_var, kld_weight)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kld_loss += kld_loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_recon_loss = total_recon_loss / len(train_loader)\n",
    "        avg_kld_loss = total_kld_loss / len(train_loader)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            print(f'Average Loss: {avg_loss:.4f}')\n",
    "            print(f'Reconstruction Loss: {avg_recon_loss:.4f}')\n",
    "            print(f'KLD Loss: {avg_kld_loss:.4f}')\n",
    "            \n",
    "            # Get and print feature importance distribution\n",
    "            importance = model.attention.get_feature_importance()\n",
    "            sorted_importance, indices = torch.sort(importance, descending=True)\n",
    "            \n",
    "            print(\"\\nTop 10 most important features:\")\n",
    "            for idx, value in zip(indices[:10], sorted_importance[:10]):\n",
    "                print(f\"Feature {idx.item()}: {value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 데이터 준비\n",
    "vector1 = np.load('saved/default_bagged_resnet_feature.npy')\n",
    "vector2 = np.load('saved/default_bagged_vit_feature.npy')\n",
    "vector3 = np.load('saved/default_bagged_dino_feature.npy')\n",
    "vector4 = np.load('saved/default_bagged_deit_feature.npy')\n",
    "\n",
    "processor = FeatureProcessor()\n",
    "concatenated_features = processor.normalize_and_concatenate([vector1, vector2, vector3, vector4])\n",
    "\n",
    "data_tensor = torch.FloatTensor(concatenated_features)\n",
    "dataset = TensorDataset(data_tensor)\n",
    "batch_size = 64  # Reduced batch size for better stability\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "input_dim = concatenated_features.shape[1]\n",
    "encoding_dim = 1024\n",
    "group_size = 128  # Increased group size\n",
    "model = AttentionVAE(input_dim, encoding_dim, group_size).to(device)\n",
    "\n",
    "# 학습 파라미터\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델 학습\n",
    "train_attention_vae(model, train_loader, num_epochs, learning_rate, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_vectors, processor, device, batch_size=64):\n",
    "    \"\"\"\n",
    "    새로운 데이터에 대한 예측 수행\n",
    "    \n",
    "    Parameters:\n",
    "    - model: 학습된 VAE 모델\n",
    "    - input_vectors: list of numpy arrays [vector1, vector2, vector3, vector4]\n",
    "    - processor: 학습에 사용된 FeatureProcessor 인스턴스\n",
    "    - device: 'cuda' or 'cpu'\n",
    "    - batch_size: 배치 크기\n",
    "    \n",
    "    Returns:\n",
    "    - reconstructed_data: 재구성된 데이터\n",
    "    - encoded_features: 인코딩된 특징\n",
    "    - feature_importance: 각 특징의 중요도\n",
    "    \"\"\"\n",
    "    model.eval()  # 평가 모드로 설정\n",
    "    \n",
    "    # 입력 데이터 전처리\n",
    "    concatenated_features = processor.normalize_and_concatenate(input_vectors)\n",
    "    data_tensor = torch.FloatTensor(concatenated_features)\n",
    "    dataset = TensorDataset(data_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    reconstructed_chunks = []\n",
    "    encoded_chunks = []\n",
    "    feature_importance = None\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for batch in dataloader:\n",
    "            inputs = batch[0].to(device)\n",
    "            \n",
    "            # 모델 통과\n",
    "            reconstructed, mu, _ = model(inputs)\n",
    "            \n",
    "            # 결과 저장\n",
    "            reconstructed_chunks.append(reconstructed.cpu().numpy())\n",
    "            encoded_chunks.append(mu.cpu().numpy())\n",
    "        \n",
    "        # Feature importance 계산\n",
    "        feature_importance = model.attention.get_feature_importance().cpu().numpy()\n",
    "    \n",
    "    # 결과 합치기\n",
    "    reconstructed_data = np.concatenate(reconstructed_chunks, axis=0)\n",
    "    encoded_features = np.concatenate(encoded_chunks, axis=0)\n",
    "    \n",
    "    return reconstructed_data, encoded_features, feature_importance\n",
    "\n",
    "def analyze_reconstruction_quality(original_data, reconstructed_data):\n",
    "    \"\"\"\n",
    "    재구성 품질 분석\n",
    "    \"\"\"\n",
    "    # MSE 계산\n",
    "    mse = np.mean((original_data - reconstructed_data) ** 2)\n",
    "    \n",
    "    # Feature별 MSE 계산\n",
    "    feature_mse = np.mean((original_data - reconstructed_data) ** 2, axis=0)\n",
    "    \n",
    "    # 상위/하위 10개 feature의 재구성 품질\n",
    "    worst_features = np.argsort(feature_mse)[-10:]\n",
    "    best_features = np.argsort(feature_mse)[:10]\n",
    "    \n",
    "    print(\"\\nReconstruction Quality Analysis:\")\n",
    "    print(f\"Overall MSE: {mse:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest Reconstructed Features:\")\n",
    "    for idx in best_features:\n",
    "        print(f\"Feature {idx}: MSE = {feature_mse[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nWorst Reconstructed Features:\")\n",
    "    for idx in worst_features:\n",
    "        print(f\"Feature {idx}: MSE = {feature_mse[idx]:.4f}\")\n",
    "    \n",
    "    return mse, feature_mse\n",
    "\n",
    "def visualize_feature_importance(feature_importance, top_k=20):\n",
    "    \"\"\"\n",
    "    Feature importance 시각화\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Top-k 중요 특징 선택\n",
    "    top_indices = np.argsort(feature_importance)[-top_k:]\n",
    "    top_importance = feature_importance[top_indices]\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(top_k), top_importance[::-1])\n",
    "    plt.title('Top Feature Importance')\n",
    "    plt.xlabel('Feature Rank')\n",
    "    plt.ylabel('Importance Score')\n",
    "    plt.xticks(range(top_k), [f'Feature {idx}' for idx in top_indices[::-1]], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시:\n",
    "def predict_example():\n",
    "    # 모델과 프로세서 로드 (이미 학습된 상태라고 가정)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 새로운 데이터 준비 (예시)\n",
    "    vector1 = np.load('saved/default_bagged_resnet_feature.npy')\n",
    "    vector2 = np.load('saved/default_bagged_vit_feature.npy')\n",
    "    vector3 = np.load('saved/default_bagged_dino_feature.npy')\n",
    "    vector4 = np.load('saved/default_bagged_deit_feature.npy')\n",
    "    \n",
    "    # 예측 수행\n",
    "    reconstructed_data, encoded_features, feature_importance = predict(\n",
    "        model, \n",
    "        [vector1, vector2, vector3, vector4],\n",
    "        processor,\n",
    "        device\n",
    "    )\n",
    "    \n",
    "    # 원본 데이터 준비 (concatenated)\n",
    "    original_data = processor.normalize_and_concatenate(\n",
    "        [vector1, vector2, vector3, vector4]\n",
    "    )\n",
    "    \n",
    "    # 재구성 품질 분석\n",
    "    mse, feature_mse = analyze_reconstruction_quality(original_data, reconstructed_data)\n",
    "    \n",
    "    # Feature importance 시각화\n",
    "    visualize_feature_importance(feature_importance)\n",
    "    \n",
    "    print(f\"\\nEncoded feature shape: {encoded_features.shape}\")\n",
    "    print(f\"Reconstructed data shape: {reconstructed_data.shape}\")\n",
    "    \n",
    "    return reconstructed_data, encoded_features, feature_importance\n",
    "\n",
    "reconstructed_data, encoded_features, importance = predict_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
